{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd02fdc0bfdba673fe1b61c92862d62105d983c1bbd13db1fe15e9268c7ddfc90cc",
   "display_name": "Python 3.9.1 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "2fdc0bfdba673fe1b61c92862d62105d983c1bbd13db1fe15e9268c7ddfc90cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pywt\n",
    "import numpy\n",
    "import os\n",
    "import pandas\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haar_wavelet(img, counter = 3):\n",
    "    if (counter == 0):\n",
    "        return img.flatten()\n",
    "    LL, (LH_, HL_, HH_) = pywt.dwt2(img, 'haar') # LL corresponds to the top left quad of the picture \n",
    "    return haar_wavelet(LL, counter - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 113.625  209.875 1028.5   ...  417.375  492.75  1014.375]\n [ 109.     215.    1034.375 ...  438.75   492.875  945.5  ]\n [ 104.625  186.25  1005.75  ...  397.625  475.625 1014.625]\n ...\n [  47.     514.    1692.875 ...  774.875 1371.5    582.5  ]\n [  41.     628.625 1755.125 ...  670.25  1437.375  585.125]\n [  42.625  584.875 1729.125 ...  692.375 1427.875  577.125]]\n"
     ]
    }
   ],
   "source": [
    "images_folder = \"../CK+48/\"\n",
    "\n",
    "column_names = [i for i in range(0,36)]\n",
    "image_coeffs = []\n",
    "emotions = []\n",
    "\n",
    "for dirname, dirs, files in os.walk(images_folder):\n",
    "    for filename in files:\n",
    "        image_to_read = numpy.asarray(Image.open(\"../CK+48/\" + dirname + \"/\" + filename))\n",
    "        coeffs = haar_wavelet(image_to_read)\n",
    "        image_coeffs.append(coeffs)\n",
    "        emotions.append(dirname.rsplit(\"/\",1)[-1])\n",
    "\n",
    "image_coeffs = numpy.array(image_coeffs)\n",
    "print(image_coeffs)\n",
    "images_df = pandas.DataFrame(image_coeffs, columns=column_names)\n",
    "images_df[\"emotion\"] = emotions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          0         1         2         3         4        5        6   \\\n835  160.625   346.750   421.750   704.875   214.875  316.375  128.250   \n396  202.500  1223.250  1887.125  1727.875  1341.375  515.250  201.375   \n91   342.500  1353.500  1946.625  1987.625  1557.250  577.000  428.375   \n633  193.375   837.750  1421.375  1460.625   822.000  107.750  226.500   \n653  846.250  1142.500  1469.375  1431.375  1040.375  832.750  508.250   \n..       ...       ...       ...       ...       ...      ...      ...   \n399  488.750  1520.625  1867.000  1637.875   851.875  566.500  425.000   \n141  387.875   402.250   649.500  1098.500   494.250  539.750  557.375   \n757  658.500   978.000  2024.375  1999.000  1059.500  686.875  518.250   \n245   57.625  1074.375  1668.125  1324.875   307.375   50.125  301.500   \n262   52.500   426.000   468.375   793.250   278.875  110.875  182.875   \n\n           7         8         9   ...        26        27        28  \\\n835   658.250  1092.250  1186.625  ...   851.500   920.375  1242.875   \n396  1344.625  1739.625  1797.875  ...  1154.000  1335.125  1696.125   \n91   1268.750  1618.375  1619.125  ...  1165.625  1363.250  1424.500   \n633   838.000  1248.500  1342.625  ...   617.750   768.000   883.000   \n653  1130.375  1087.750  1039.250  ...   698.375   571.625   623.250   \n..        ...       ...       ...  ...       ...       ...       ...   \n399  1829.375  1837.375  1854.875  ...  1460.250  1669.875  1766.000   \n141   767.500  1402.125  1478.500  ...  1316.375  1412.250  1584.125   \n757  1410.500  1806.125  1793.000  ...  1516.000  1620.875  1929.750   \n245  1185.375  1538.000  1633.750  ...  1254.500  1299.875  1508.125   \n262   866.250  1335.500  1400.500  ...   947.875  1035.875  1387.875   \n\n           29        30        31        32        33        34        35  \n835   684.625   421.750   719.750   680.000   786.875  1132.875   637.625  \n396   310.500    53.875   646.000  1283.000  1506.375  1037.125   167.375  \n91    673.750   421.375   687.125  1264.750  1399.125  1291.000   521.500  \n633   757.500   310.000   656.000   921.625  1026.500   917.000   393.625  \n653   153.375   247.000   230.375   396.875   349.000   205.875    37.625  \n..        ...       ...       ...       ...       ...       ...       ...  \n399  1615.500   396.750   979.750  1927.625  2030.750  1831.750   626.625  \n141  1303.875   931.125  1235.625  1452.125  1530.625  1264.375  1142.500  \n757  1689.000  1109.875  1519.375   830.250   958.375  1677.375   992.875  \n245   708.000    82.875  1065.875  1362.625  1430.875  1339.875   389.500  \n262   893.875   410.250   685.750   806.750   971.375  1102.875   721.125  \n\n[686 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "features = images_df.loc[:, column_names]\n",
    "outcome = images_df.emotion\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, outcome, test_size=0.3,random_state=109) # 70% training and 30% test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}